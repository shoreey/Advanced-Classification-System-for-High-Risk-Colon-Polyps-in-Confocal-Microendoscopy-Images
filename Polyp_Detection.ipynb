{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoreey/Advanced-Classification-System-for-High-Risk-Colon-Polyps-in-Confocal-Microendoscopy-Images/blob/main/Polyp_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMtFCfV1pvyR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import io\n",
        "import pandas as pd\n",
        "import random\n",
        "import scipy.io as sio\n",
        "from scipy import ndimage\n",
        "import scipy\n",
        "from skimage.transform import resize\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from functools import partial\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import copy\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "4s9zCOXOpvyT"
      },
      "outputs": [],
      "source": [
        "#read excel file\n",
        "BASE_DIR='.\\MI_Data'\n",
        "data_df = pd.read_excel(\".\\MI_polyps_clear.xlsx\")\n",
        "data_df.head()\n",
        "#print (data_df)\n",
        "\n",
        "num_classes = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZwYSR7JpvyT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BrUEetwpvyT"
      },
      "outputs": [],
      "source": [
        "class Polyps_Dataset(Dataset):\n",
        "    def __init__(self,df:pd.DataFrame,imfolder:str,train:bool = True, transforms=None):\n",
        "        self.df=df\n",
        "        self.imfolder=imfolder\n",
        "        self.train=train\n",
        "        self.transforms=transforms\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        filename=self.df.iloc[index]['fp'];\n",
        "\n",
        "        im_path=os.path.join(self.imfolder,filename.strip())\n",
        "        data = sio.loadmat(im_path)\n",
        "        xstack=data['xstack']\n",
        "        sz=xstack.shape\n",
        "        #print(sz)\n",
        "        #x = torch.from_numpy(data['xstack'])\n",
        "        if(len(sz)<3):\n",
        "            x=torch.zeros([1,3,224,224])\n",
        "            tmp=Image.fromarray(xstack).convert('RGB')\n",
        "            if(self.transforms):\n",
        "                tmp=self.transforms(tmp)\n",
        "            x[0,:,:,:]=tmp.type(torch.FloatTensor);\n",
        "        else:\n",
        "            x=torch.zeros([sz[2],3,224,224])\n",
        "\n",
        "            for ct in range(sz[2]):\n",
        "                tmp=Image.fromarray(xstack[:,:,ct]).convert('RGB')\n",
        "                if(self.transforms):\n",
        "                    tmp=self.transforms(tmp)\n",
        "                x[ct,:,:,:]=tmp.type(torch.FloatTensor);\n",
        "\n",
        "        if(self.train):\n",
        "            y=self.df.iloc[index]['Class2']\n",
        "            return x,y\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejy9dj26pvyU"
      },
      "outputs": [],
      "source": [
        "train, valid = train_test_split(\n",
        "    data_df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=data_df.Class2\n",
        ")\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "def my_collate(batch):\n",
        "    data=torch.tensor([])\n",
        "    target=torch.tensor([])\n",
        "    pat=torch.tensor([])\n",
        "\n",
        "    for index, item in enumerate(batch):\n",
        "        sz=item[0].size()\n",
        "        data=torch.cat((data,item[0]),dim=0)\n",
        "\n",
        "        lab=torch.ones(sz[0],)*item[1].astype(int)\n",
        "        target=torch.cat((target,lab),dim=0)\n",
        "\n",
        "        inst=torch.ones(sz[0],)*index\n",
        "        pat=torch.cat((pat,inst),dim=0)\n",
        "\n",
        "    data=data.unsqueeze(1)\n",
        "    return [data, target, pat]\n",
        "\n",
        "# reset index on both dataframes\n",
        "train = train.reset_index(drop=True)\n",
        "valid = valid.reset_index(drop=True)\n",
        "\n",
        "train_targets = train.Class2.values\n",
        "\n",
        "# targets for validation\n",
        "valid_targets = valid.Class2.values\n",
        "\n",
        "train_dataset=Polyps_Dataset(\n",
        "    df=train,\n",
        "    imfolder=BASE_DIR,\n",
        "    train=True,\n",
        "    transforms=train_transform\n",
        ")\n",
        "\n",
        "valid_dataset=Polyps_Dataset(\n",
        "    df=valid,\n",
        "    imfolder=BASE_DIR,\n",
        "    train=True,\n",
        "    transforms=valid_transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=1,\n",
        "    #num_workers=4,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=1,\n",
        "    #num_workers=4,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXgbwV66pvyU",
        "outputId": "7616ee41-ab19-4cc3-914a-59773acf3305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: torch in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from efficientnet_pytorch) (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (2024.3.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (69.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shaur\\anaconda3\\lib\\site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py): started\n",
            "  Building wheel for efficientnet_pytorch (setup.py): finished with status 'done'\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16464 sha256=4f72b375478e49690891a1df62c127b5a6e10b360a0a6ada789c600ff0e534dc\n",
            "  Stored in directory: c:\\users\\shaur\\appdata\\local\\pip\\cache\\wheels\\9c\\3f\\43\\e6271c7026fe08c185da2be23c98c8e87477d3db63f41f32ad\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to C:\\Users\\shaur/.cache\\torch\\hub\\checkpoints\\efficientnet-b0-355c32eb.pth\n",
            "100%|██████████| 20.4M/20.4M [00:01<00:00, 16.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'num_classes' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Replacing the last layer and unfreezing it\u001b[39;00m\n\u001b[0;32m     11\u001b[0m num_ftrs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_fc\u001b[38;5;241m.\u001b[39min_features\n\u001b[1;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39m_fc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_ftrs, num_classes)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'num_classes' is not defined"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet_pytorch\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "# Freezing the entire model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replacing the last layer and unfreezing it\n",
        "num_ftrs = model._fc.in_features\n",
        "model._fc = nn.Linear(num_ftrs, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeAZh6FkpvyU"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "ct = 0\n",
        "for child in model.children():\n",
        "    ct += 1\n",
        "    if ct < 7:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS7hWAq8pvyV"
      },
      "outputs": [],
      "source": [
        "def train_model(datasets, dataloaders, model, criterion, optimizer, scheduler, num_epochs, device, class_weights):\n",
        "\n",
        "    N_iter_internal = 10\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 100.0\n",
        "    best_acc=0.0\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        preds=np.empty((0,1))\n",
        "        targets=np.empty((0,1))\n",
        "\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corr = 0.0\n",
        "            running_corrects = 0.0\n",
        "            running_corrects_0=0.0\n",
        "            running_corrects_1=0.0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels=labels.type(torch.FloatTensor).to(device)\n",
        "\n",
        "                # Zero out the grads\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                # Track history in train mode\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    model=model.to(device)\n",
        "                    outputs = model(inputs.squeeze(0))\n",
        "\n",
        "                    ###############################################################################\n",
        "                    #Multiclass MIL\n",
        "                    #score=torch.ones((4,)).to(device)\n",
        "                    #score[3]=1-torch.exp(-torch.sum(p[:,3],dim=0))\n",
        "                    #score[2]=(1-score[3])*(1-torch.exp(-torch.sum(p[:,2],dim=0)))\n",
        "                    #score[1]=(1-score[3])*(1-score[2])*(1-torch.exp(-torch.sum(p[:,1],dim=0)))\n",
        "                    #score[0]=(1-score[3])*(1-score[2])*(1-score[1])*(1-torch.exp(-torch.sum(p[:,0],dim=0)))\n",
        "                    #pred=torch.argmax(score)\n",
        "                    ###############################################################################\n",
        "\n",
        "\n",
        "                    #loss=criterion(score.unsqueeze(0),labels-1)\n",
        "                    #loss=criterion(score,labels)\n",
        "\n",
        "                    #p=torch.nn.functional.softmax(outputs,dim=1)\n",
        "                    p=torch.sigmoid(outputs)\n",
        "                    #score=torch.zeros(1,2).to(device)\n",
        "                    #score[0,1]=1-torch.exp(-torch.sum(p[:,1],dim=0))\n",
        "                    #score[0,0]=torch.exp(-torch.sum(p[:,1],dim=0))\n",
        "                    score=1-torch.exp(-torch.sum(p,dim=0))\n",
        "                    loss=criterion(score,labels)\n",
        "                    if labels==0:\n",
        "                        loss=class_weight[0]*criterion(score,labels)\n",
        "                    else:\n",
        "                        loss=class_weight[1]*criterion(score,labels)\n",
        "\n",
        "                    pred=torch.argmax(score)\n",
        "                    #batch_score=MIL_aggregator(outputs,1)\n",
        "                    #loss = criterion(batch_score.unsqueeze(0).to(device), (scores/15).type(torch.FloatTensor).to(device))\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item()*inputs.size(0)\n",
        "                running_corrects += torch.sum(pred==(labels))\n",
        "                if(labels==0 and score<=0.5):#[0]>batch_score[1]):\n",
        "                    running_corrects_0 += 1\n",
        "                if(labels==1 and score>0.5):#[1]>batch_score[0]):\n",
        "                    running_corrects_1 += 1\n",
        "\n",
        "                #running_corrects_0 += torch.sum(batch_score[labels==0] == labels.data[labels.data==0])\n",
        "                #running_corrects_1 += torch.sum(batch_score[labels.data==1] == labels.data[labels.data==1])\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss/len(datasets[phase])\n",
        "            epoch_acc = (running_corrects)/(len(datasets[phase]))\n",
        "            acc_0=running_corrects_0/(sum(datasets[phase].df['Class2']==0))\n",
        "            acc_1=running_corrects_1/(sum(datasets[phase].df['Class2']==1))\n",
        "            epoch_balacc = 0.5*(acc_0+acc_1)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f} Balanced Acc: {:.4f}  Acc 0: {:.4f}  Acc 1: {:.4f}'.format(phase, epoch_loss, epoch_acc, epoch_balacc,acc_0,acc_1))\n",
        "\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), 'Polyps_ResNet_binaryclass_MIL.pth')\n",
        "\n",
        "\n",
        "            #if phase == 'valid':\n",
        "            #    plt.plot(targets,preds,'o')\n",
        "            #    plt.show()\n",
        "\n",
        "            #if phase == 'valid' and epoch_loss < best_loss:\n",
        "            #    best_loss = epoch_loss\n",
        "            #    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            print()\n",
        "\n",
        "    time_elapsed = time.time()-since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24y-889tpvyV",
        "outputId": "fae8dea4-f0de-416c-ee2a-eef4ee02e4fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.0000, 0.3661])\n",
            "[ 41 112]\n"
          ]
        }
      ],
      "source": [
        "class_sample_count = np.array([len(np.where(train_targets == t)[0]) for t in np.unique(train_targets)])\n",
        "weight = 1. / class_sample_count\n",
        "class_weight=torch.from_numpy(weight)\n",
        "class_weight=class_weight/class_weight.max()\n",
        "class_weight=class_weight.type(torch.FloatTensor)\n",
        "print(class_weight)\n",
        "print(class_sample_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wctrJwDLpvyV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFRKHP6WpvyV",
        "outputId": "9c618450-c1da-4aef-9ff4-79752a9cd24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/99\n",
            "----------\n",
            "train Loss: 0.4387 Acc: 0.2680 Balanced Acc: 0.4546  Acc 0: 0.5610  Acc 1: 0.3482\n",
            "\n",
            "valid Loss: 0.3753 Acc: 0.2821 Balanced Acc: 0.5049  Acc 0: 0.5455  Acc 1: 0.4643\n",
            "\n",
            "Epoch 1/99\n",
            "----------\n",
            "train Loss: 0.4352 Acc: 0.2680 Balanced Acc: 0.5058  Acc 0: 0.6098  Acc 1: 0.4018\n",
            "\n",
            "valid Loss: 0.4139 Acc: 0.2821 Balanced Acc: 0.4545  Acc 0: 0.9091  Acc 1: 0.0000\n",
            "\n",
            "Epoch 2/99\n",
            "----------\n",
            "train Loss: 0.4171 Acc: 0.2680 Balanced Acc: 0.4932  Acc 0: 0.6829  Acc 1: 0.3036\n",
            "\n",
            "valid Loss: 0.3973 Acc: 0.2821 Balanced Acc: 0.5195  Acc 0: 0.1818  Acc 1: 0.8571\n",
            "\n",
            "Epoch 3/99\n",
            "----------\n",
            "train Loss: 0.4356 Acc: 0.2680 Balanced Acc: 0.4594  Acc 0: 0.4634  Acc 1: 0.4554\n",
            "\n",
            "valid Loss: 0.3767 Acc: 0.2821 Balanced Acc: 0.5406  Acc 0: 0.5455  Acc 1: 0.5357\n",
            "\n",
            "Epoch 4/99\n",
            "----------\n",
            "train Loss: 0.4338 Acc: 0.2680 Balanced Acc: 0.4501  Acc 0: 0.5610  Acc 1: 0.3393\n",
            "\n",
            "valid Loss: 0.3789 Acc: 0.2821 Balanced Acc: 0.5844  Acc 0: 0.4545  Acc 1: 0.7143\n",
            "\n",
            "Epoch 5/99\n",
            "----------\n",
            "train Loss: 0.4320 Acc: 0.2680 Balanced Acc: 0.4525  Acc 0: 0.5122  Acc 1: 0.3929\n",
            "\n",
            "valid Loss: 0.3786 Acc: 0.2821 Balanced Acc: 0.6120  Acc 0: 0.5455  Acc 1: 0.6786\n",
            "\n",
            "Epoch 6/99\n",
            "----------\n",
            "train Loss: 0.4203 Acc: 0.2680 Balanced Acc: 0.4960  Acc 0: 0.5366  Acc 1: 0.4554\n",
            "\n",
            "valid Loss: 0.3829 Acc: 0.2821 Balanced Acc: 0.5471  Acc 0: 0.2727  Acc 1: 0.8214\n",
            "\n",
            "Epoch 7/99\n",
            "----------\n",
            "train Loss: 0.4367 Acc: 0.2680 Balanced Acc: 0.4846  Acc 0: 0.5854  Acc 1: 0.3839\n",
            "\n",
            "valid Loss: 0.3769 Acc: 0.2821 Balanced Acc: 0.5763  Acc 0: 0.5455  Acc 1: 0.6071\n",
            "\n",
            "Epoch 8/99\n",
            "----------\n",
            "train Loss: 0.4352 Acc: 0.2680 Balanced Acc: 0.5501  Acc 0: 0.7073  Acc 1: 0.3929\n",
            "\n",
            "valid Loss: 0.3841 Acc: 0.2821 Balanced Acc: 0.5925  Acc 0: 0.3636  Acc 1: 0.8214\n",
            "\n",
            "Epoch 9/99\n",
            "----------\n",
            "train Loss: 0.4247 Acc: 0.2680 Balanced Acc: 0.4671  Acc 0: 0.4878  Acc 1: 0.4464\n",
            "\n",
            "valid Loss: 0.3776 Acc: 0.2821 Balanced Acc: 0.5666  Acc 0: 0.4545  Acc 1: 0.6786\n",
            "\n",
            "Epoch 10/99\n",
            "----------\n",
            "train Loss: 0.4380 Acc: 0.2680 Balanced Acc: 0.4513  Acc 0: 0.5366  Acc 1: 0.3661\n",
            "\n",
            "valid Loss: 0.3788 Acc: 0.2821 Balanced Acc: 0.6201  Acc 0: 0.4545  Acc 1: 0.7857\n",
            "\n",
            "Epoch 11/99\n",
            "----------\n",
            "train Loss: 0.4259 Acc: 0.2680 Balanced Acc: 0.4992  Acc 0: 0.5610  Acc 1: 0.4375\n",
            "\n",
            "valid Loss: 0.3837 Acc: 0.2821 Balanced Acc: 0.5422  Acc 0: 0.7273  Acc 1: 0.3571\n",
            "\n",
            "Epoch 12/99\n",
            "----------\n",
            "train Loss: 0.4114 Acc: 0.2680 Balanced Acc: 0.5147  Acc 0: 0.6098  Acc 1: 0.4196\n",
            "\n",
            "valid Loss: 0.4007 Acc: 0.2821 Balanced Acc: 0.5195  Acc 0: 0.1818  Acc 1: 0.8571\n",
            "\n",
            "Epoch 13/99\n",
            "----------\n",
            "train Loss: 0.4366 Acc: 0.2680 Balanced Acc: 0.4058  Acc 0: 0.4634  Acc 1: 0.3482\n",
            "\n",
            "valid Loss: 0.3820 Acc: 0.2821 Balanced Acc: 0.6380  Acc 0: 0.4545  Acc 1: 0.8214\n",
            "\n",
            "Epoch 14/99\n",
            "----------\n",
            "train Loss: 0.4343 Acc: 0.2680 Balanced Acc: 0.4936  Acc 0: 0.5854  Acc 1: 0.4018\n",
            "\n",
            "valid Loss: 0.4112 Acc: 0.2821 Balanced Acc: 0.4545  Acc 0: 0.9091  Acc 1: 0.0000\n",
            "\n",
            "Epoch 15/99\n",
            "----------\n",
            "train Loss: 0.4335 Acc: 0.2680 Balanced Acc: 0.4611  Acc 0: 0.6098  Acc 1: 0.3125\n",
            "\n",
            "valid Loss: 0.3782 Acc: 0.2821 Balanced Acc: 0.5763  Acc 0: 0.5455  Acc 1: 0.6071\n",
            "\n",
            "Epoch 16/99\n",
            "----------\n",
            "train Loss: 0.4170 Acc: 0.2680 Balanced Acc: 0.5346  Acc 0: 0.6585  Acc 1: 0.4107\n",
            "\n",
            "valid Loss: 0.3795 Acc: 0.2821 Balanced Acc: 0.5227  Acc 0: 0.5455  Acc 1: 0.5000\n",
            "\n",
            "Epoch 17/99\n",
            "----------\n",
            "train Loss: 0.4286 Acc: 0.2680 Balanced Acc: 0.4338  Acc 0: 0.4390  Acc 1: 0.4286\n",
            "\n",
            "valid Loss: 0.4279 Acc: 0.2821 Balanced Acc: 0.5000  Acc 0: 1.0000  Acc 1: 0.0000\n",
            "\n",
            "Epoch 18/99\n",
            "----------\n",
            "train Loss: 0.4321 Acc: 0.2680 Balanced Acc: 0.4400  Acc 0: 0.5854  Acc 1: 0.2946\n",
            "\n",
            "valid Loss: 0.3859 Acc: 0.2821 Balanced Acc: 0.5471  Acc 0: 0.2727  Acc 1: 0.8214\n",
            "\n",
            "Epoch 19/99\n",
            "----------\n",
            "train Loss: 0.4255 Acc: 0.2680 Balanced Acc: 0.5412  Acc 0: 0.7073  Acc 1: 0.3750\n",
            "\n",
            "valid Loss: 0.3937 Acc: 0.2821 Balanced Acc: 0.5471  Acc 0: 0.2727  Acc 1: 0.8214\n",
            "\n",
            "Epoch 20/99\n",
            "----------\n",
            "train Loss: 0.4314 Acc: 0.2680 Balanced Acc: 0.5102  Acc 0: 0.6098  Acc 1: 0.4107\n",
            "\n",
            "valid Loss: 0.3943 Acc: 0.2821 Balanced Acc: 0.5081  Acc 0: 0.9091  Acc 1: 0.1071\n",
            "\n",
            "Epoch 21/99\n",
            "----------\n",
            "train Loss: 0.4343 Acc: 0.2680 Balanced Acc: 0.5334  Acc 0: 0.6829  Acc 1: 0.3839\n",
            "\n",
            "valid Loss: 0.4036 Acc: 0.2821 Balanced Acc: 0.4903  Acc 0: 0.9091  Acc 1: 0.0714\n",
            "\n",
            "Epoch 22/99\n",
            "----------\n",
            "train Loss: 0.4320 Acc: 0.2680 Balanced Acc: 0.4635  Acc 0: 0.5610  Acc 1: 0.3661\n",
            "\n",
            "valid Loss: 0.3786 Acc: 0.2821 Balanced Acc: 0.5049  Acc 0: 0.5455  Acc 1: 0.4643\n",
            "\n",
            "Epoch 23/99\n",
            "----------\n",
            "train Loss: 0.4396 Acc: 0.2680 Balanced Acc: 0.5168  Acc 0: 0.6585  Acc 1: 0.3750\n",
            "\n",
            "valid Loss: 0.4058 Acc: 0.2821 Balanced Acc: 0.5081  Acc 0: 0.9091  Acc 1: 0.1071\n",
            "\n",
            "Epoch 24/99\n",
            "----------\n",
            "train Loss: 0.4328 Acc: 0.2680 Balanced Acc: 0.4713  Acc 0: 0.5854  Acc 1: 0.3571\n",
            "\n",
            "valid Loss: 0.3897 Acc: 0.2821 Balanced Acc: 0.5617  Acc 0: 0.9091  Acc 1: 0.2143\n",
            "\n",
            "Epoch 25/99\n",
            "----------\n",
            "train Loss: 0.4252 Acc: 0.2680 Balanced Acc: 0.5468  Acc 0: 0.6829  Acc 1: 0.4107\n",
            "\n",
            "valid Loss: 0.3791 Acc: 0.2821 Balanced Acc: 0.5325  Acc 0: 0.6364  Acc 1: 0.4286\n",
            "\n",
            "Epoch 26/99\n",
            "----------\n",
            "train Loss: 0.4268 Acc: 0.2680 Balanced Acc: 0.5269  Acc 0: 0.6341  Acc 1: 0.4196\n",
            "\n",
            "valid Loss: 0.3970 Acc: 0.2821 Balanced Acc: 0.5260  Acc 0: 0.9091  Acc 1: 0.1429\n",
            "\n",
            "Epoch 27/99\n",
            "----------\n",
            "train Loss: 0.4388 Acc: 0.2680 Balanced Acc: 0.4522  Acc 0: 0.6098  Acc 1: 0.2946\n",
            "\n",
            "valid Loss: 0.3849 Acc: 0.2821 Balanced Acc: 0.5341  Acc 0: 0.8182  Acc 1: 0.2500\n",
            "\n",
            "Epoch 28/99\n",
            "----------\n",
            "train Loss: 0.4251 Acc: 0.2680 Balanced Acc: 0.4834  Acc 0: 0.6098  Acc 1: 0.3571\n",
            "\n",
            "valid Loss: 0.3970 Acc: 0.2821 Balanced Acc: 0.5471  Acc 0: 0.2727  Acc 1: 0.8214\n",
            "\n",
            "Epoch 29/99\n",
            "----------\n",
            "train Loss: 0.4403 Acc: 0.2680 Balanced Acc: 0.4403  Acc 0: 0.4878  Acc 1: 0.3929\n",
            "\n",
            "valid Loss: 0.3881 Acc: 0.2821 Balanced Acc: 0.5162  Acc 0: 0.8182  Acc 1: 0.2143\n",
            "\n",
            "Epoch 30/99\n",
            "----------\n",
            "train Loss: 0.4097 Acc: 0.2680 Balanced Acc: 0.4823  Acc 0: 0.6341  Acc 1: 0.3304\n",
            "\n",
            "valid Loss: 0.4308 Acc: 0.2821 Balanced Acc: 0.5195  Acc 0: 0.1818  Acc 1: 0.8571\n",
            "\n",
            "Epoch 31/99\n",
            "----------\n",
            "train Loss: 0.4281 Acc: 0.2680 Balanced Acc: 0.4561  Acc 0: 0.4390  Acc 1: 0.4732\n",
            "\n",
            "valid Loss: 0.3951 Acc: 0.2821 Balanced Acc: 0.5438  Acc 0: 0.9091  Acc 1: 0.1786\n",
            "\n",
            "Epoch 32/99\n",
            "----------\n",
            "train Loss: 0.4168 Acc: 0.2680 Balanced Acc: 0.5403  Acc 0: 0.6341  Acc 1: 0.4464\n",
            "\n",
            "valid Loss: 0.3992 Acc: 0.2821 Balanced Acc: 0.5016  Acc 0: 0.1818  Acc 1: 0.8214\n",
            "\n",
            "Epoch 33/99\n",
            "----------\n",
            "train Loss: 0.4289 Acc: 0.2680 Balanced Acc: 0.5070  Acc 0: 0.5854  Acc 1: 0.4286\n",
            "\n",
            "valid Loss: 0.3911 Acc: 0.2821 Balanced Acc: 0.5471  Acc 0: 0.2727  Acc 1: 0.8214\n",
            "\n",
            "Epoch 34/99\n",
            "----------\n",
            "train Loss: 0.4368 Acc: 0.2680 Balanced Acc: 0.4668  Acc 0: 0.5854  Acc 1: 0.3482\n",
            "\n",
            "valid Loss: 0.3861 Acc: 0.2821 Balanced Acc: 0.6120  Acc 0: 0.5455  Acc 1: 0.6786\n",
            "\n",
            "Epoch 35/99\n",
            "----------\n",
            "train Loss: 0.4221 Acc: 0.2680 Balanced Acc: 0.5171  Acc 0: 0.5610  Acc 1: 0.4732\n",
            "\n",
            "valid Loss: 0.4113 Acc: 0.2821 Balanced Acc: 0.4903  Acc 0: 0.9091  Acc 1: 0.0714\n",
            "\n",
            "Epoch 36/99\n",
            "----------\n",
            "train Loss: 0.4287 Acc: 0.2680 Balanced Acc: 0.4644  Acc 0: 0.6341  Acc 1: 0.2946\n",
            "\n",
            "valid Loss: 0.3881 Acc: 0.2821 Balanced Acc: 0.6299  Acc 0: 0.5455  Acc 1: 0.7143\n",
            "\n",
            "Epoch 37/99\n",
            "----------\n",
            "train Loss: 0.4335 Acc: 0.2680 Balanced Acc: 0.4924  Acc 0: 0.6098  Acc 1: 0.3750\n",
            "\n",
            "valid Loss: 0.3892 Acc: 0.2821 Balanced Acc: 0.5406  Acc 0: 0.5455  Acc 1: 0.5357\n",
            "\n",
            "Epoch 38/99\n",
            "----------\n",
            "train Loss: 0.4270 Acc: 0.2680 Balanced Acc: 0.4615  Acc 0: 0.5122  Acc 1: 0.4107\n",
            "\n",
            "valid Loss: 0.3830 Acc: 0.2821 Balanced Acc: 0.5584  Acc 0: 0.5455  Acc 1: 0.5714\n",
            "\n",
            "Epoch 39/99\n",
            "----------\n",
            "train Loss: 0.4190 Acc: 0.2680 Balanced Acc: 0.4829  Acc 0: 0.4390  Acc 1: 0.5268\n",
            "\n",
            "valid Loss: 0.4246 Acc: 0.2821 Balanced Acc: 0.4545  Acc 0: 0.9091  Acc 1: 0.0000\n",
            "\n",
            "Epoch 40/99\n",
            "----------\n",
            "train Loss: 0.4413 Acc: 0.2680 Balanced Acc: 0.5221  Acc 0: 0.7317  Acc 1: 0.3125\n",
            "\n",
            "valid Loss: 0.4112 Acc: 0.2821 Balanced Acc: 0.5081  Acc 0: 0.9091  Acc 1: 0.1071\n",
            "\n",
            "Epoch 41/99\n",
            "----------\n",
            "train Loss: 0.4303 Acc: 0.2680 Balanced Acc: 0.4745  Acc 0: 0.6098  Acc 1: 0.3393\n",
            "\n",
            "valid Loss: 0.4026 Acc: 0.2821 Balanced Acc: 0.4708  Acc 0: 0.7273  Acc 1: 0.2143\n",
            "\n",
            "Epoch 42/99\n",
            "----------\n",
            "train Loss: 0.4301 Acc: 0.2680 Balanced Acc: 0.4534  Acc 0: 0.5854  Acc 1: 0.3214\n",
            "\n",
            "valid Loss: 0.3901 Acc: 0.2821 Balanced Acc: 0.5942  Acc 0: 0.5455  Acc 1: 0.6429\n",
            "\n",
            "Epoch 43/99\n",
            "----------\n",
            "train Loss: 0.4294 Acc: 0.2680 Balanced Acc: 0.4639  Acc 0: 0.4634  Acc 1: 0.4643\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid Loss: 0.3958 Acc: 0.2821 Balanced Acc: 0.5617  Acc 0: 0.9091  Acc 1: 0.2143\n",
            "\n",
            "Epoch 44/99\n",
            "----------\n",
            "train Loss: 0.4327 Acc: 0.2680 Balanced Acc: 0.5066  Acc 0: 0.6829  Acc 1: 0.3304\n",
            "\n",
            "valid Loss: 0.4022 Acc: 0.2821 Balanced Acc: 0.5438  Acc 0: 0.9091  Acc 1: 0.1786\n",
            "\n",
            "Epoch 45/99\n",
            "----------\n",
            "train Loss: 0.4223 Acc: 0.2680 Balanced Acc: 0.4968  Acc 0: 0.6098  Acc 1: 0.3839\n",
            "\n",
            "valid Loss: 0.4132 Acc: 0.2821 Balanced Acc: 0.5081  Acc 0: 0.9091  Acc 1: 0.1071\n",
            "\n",
            "Epoch 46/99\n",
            "----------\n",
            "train Loss: 0.4317 Acc: 0.2680 Balanced Acc: 0.4924  Acc 0: 0.6098  Acc 1: 0.3750\n",
            "\n",
            "valid Loss: 0.3973 Acc: 0.2821 Balanced Acc: 0.5244  Acc 0: 0.7273  Acc 1: 0.3214\n",
            "\n",
            "Epoch 47/99\n",
            "----------\n",
            "train Loss: 0.4198 Acc: 0.2680 Balanced Acc: 0.4826  Acc 0: 0.5366  Acc 1: 0.4286\n",
            "\n",
            "valid Loss: 0.3950 Acc: 0.2821 Balanced Acc: 0.6299  Acc 0: 0.5455  Acc 1: 0.7143\n",
            "\n",
            "Epoch 48/99\n",
            "----------\n",
            "train Loss: 0.4194 Acc: 0.2680 Balanced Acc: 0.5605  Acc 0: 0.5854  Acc 1: 0.5357\n",
            "\n",
            "valid Loss: 0.4507 Acc: 0.2821 Balanced Acc: 0.4545  Acc 0: 0.9091  Acc 1: 0.0000\n",
            "\n",
            "Epoch 49/99\n",
            "----------\n",
            "train Loss: 0.4367 Acc: 0.2680 Balanced Acc: 0.5022  Acc 0: 0.6829  Acc 1: 0.3214\n",
            "\n",
            "valid Loss: 0.3899 Acc: 0.2821 Balanced Acc: 0.5584  Acc 0: 0.5455  Acc 1: 0.5714\n",
            "\n",
            "Epoch 50/99\n",
            "----------\n",
            "train Loss: 0.4076 Acc: 0.2680 Balanced Acc: 0.5959  Acc 0: 0.6829  Acc 1: 0.5089\n",
            "\n",
            "valid Loss: 0.4018 Acc: 0.2821 Balanced Acc: 0.5065  Acc 0: 0.7273  Acc 1: 0.2857\n",
            "\n",
            "Epoch 51/99\n",
            "----------\n",
            "train Loss: 0.4078 Acc: 0.2680 Balanced Acc: 0.5372  Acc 0: 0.8780  Acc 1: 0.1964\n",
            "\n",
            "valid Loss: 0.3925 Acc: 0.2821 Balanced Acc: 0.5244  Acc 0: 0.7273  Acc 1: 0.3214\n",
            "\n",
            "Epoch 52/99\n",
            "----------\n",
            "train Loss: 0.4069 Acc: 0.2680 Balanced Acc: 0.5403  Acc 0: 0.6341  Acc 1: 0.4464\n",
            "\n",
            "valid Loss: 0.4006 Acc: 0.2821 Balanced Acc: 0.4886  Acc 0: 0.7273  Acc 1: 0.2500\n",
            "\n",
            "Epoch 53/99\n",
            "----------\n",
            "train Loss: 0.4076 Acc: 0.2680 Balanced Acc: 0.5417  Acc 0: 0.8780  Acc 1: 0.2054\n",
            "\n",
            "valid Loss: 0.3900 Acc: 0.2821 Balanced Acc: 0.5601  Acc 0: 0.7273  Acc 1: 0.3929\n",
            "\n",
            "Epoch 54/99\n",
            "----------\n",
            "train Loss: 0.4085 Acc: 0.2680 Balanced Acc: 0.5328  Acc 0: 0.8780  Acc 1: 0.1875\n",
            "\n",
            "valid Loss: 0.3924 Acc: 0.2821 Balanced Acc: 0.4789  Acc 0: 0.6364  Acc 1: 0.3214\n",
            "\n",
            "Epoch 55/99\n",
            "----------\n",
            "train Loss: 0.4075 Acc: 0.2680 Balanced Acc: 0.5307  Acc 0: 0.8293  Acc 1: 0.2321\n",
            "\n",
            "valid Loss: 0.3921 Acc: 0.2821 Balanced Acc: 0.5422  Acc 0: 0.7273  Acc 1: 0.3571\n",
            "\n",
            "Epoch 56/99\n",
            "----------\n",
            "train Loss: 0.4069 Acc: 0.2680 Balanced Acc: 0.5352  Acc 0: 0.8293  Acc 1: 0.2411\n",
            "\n",
            "valid Loss: 0.3992 Acc: 0.2821 Balanced Acc: 0.4886  Acc 0: 0.7273  Acc 1: 0.2500\n",
            "\n",
            "Epoch 57/99\n",
            "----------\n",
            "train Loss: 0.4075 Acc: 0.2680 Balanced Acc: 0.5328  Acc 0: 0.8780  Acc 1: 0.1875\n",
            "\n",
            "valid Loss: 0.3979 Acc: 0.2821 Balanced Acc: 0.5065  Acc 0: 0.7273  Acc 1: 0.2857\n",
            "\n",
            "Epoch 58/99\n",
            "----------\n",
            "train Loss: 0.4079 Acc: 0.2680 Balanced Acc: 0.5506  Acc 0: 0.8780  Acc 1: 0.2232\n",
            "\n",
            "valid Loss: 0.3885 Acc: 0.2821 Balanced Acc: 0.5227  Acc 0: 0.5455  Acc 1: 0.5000\n",
            "\n",
            "Epoch 59/99\n",
            "----------\n",
            "train Loss: 0.4069 Acc: 0.2680 Balanced Acc: 0.5417  Acc 0: 0.8780  Acc 1: 0.2054\n",
            "\n",
            "valid Loss: 0.3913 Acc: 0.2821 Balanced Acc: 0.4968  Acc 0: 0.6364  Acc 1: 0.3571\n",
            "\n",
            "Epoch 60/99\n",
            "----------\n",
            "train Loss: 0.4071 Acc: 0.2680 Balanced Acc: 0.5748  Acc 0: 0.6585  Acc 1: 0.4911\n",
            "\n",
            "valid Loss: 0.4019 Acc: 0.2821 Balanced Acc: 0.4789  Acc 0: 0.6364  Acc 1: 0.3214\n",
            "\n",
            "Epoch 61/99\n",
            "----------\n",
            "train Loss: 0.4072 Acc: 0.2680 Balanced Acc: 0.5474  Acc 0: 0.8537  Acc 1: 0.2411\n",
            "\n",
            "valid Loss: 0.3924 Acc: 0.2821 Balanced Acc: 0.5146  Acc 0: 0.6364  Acc 1: 0.3929\n",
            "\n",
            "Epoch 62/99\n",
            "----------\n",
            "train Loss: 0.4066 Acc: 0.2680 Balanced Acc: 0.5506  Acc 0: 0.8780  Acc 1: 0.2232\n",
            "\n",
            "valid Loss: 0.3966 Acc: 0.2821 Balanced Acc: 0.4789  Acc 0: 0.6364  Acc 1: 0.3214\n",
            "\n",
            "Epoch 63/99\n",
            "----------\n",
            "train Loss: 0.4078 Acc: 0.2680 Balanced Acc: 0.5506  Acc 0: 0.8780  Acc 1: 0.2232\n",
            "\n",
            "valid Loss: 0.3932 Acc: 0.2821 Balanced Acc: 0.5146  Acc 0: 0.6364  Acc 1: 0.3929\n",
            "\n",
            "Epoch 64/99\n",
            "----------\n",
            "train Loss: 0.4086 Acc: 0.2680 Balanced Acc: 0.5328  Acc 0: 0.8780  Acc 1: 0.1875\n",
            "\n",
            "valid Loss: 0.4000 Acc: 0.2821 Balanced Acc: 0.4886  Acc 0: 0.7273  Acc 1: 0.2500\n",
            "\n",
            "Epoch 65/99\n",
            "----------\n",
            "train Loss: 0.4082 Acc: 0.2680 Balanced Acc: 0.5462  Acc 0: 0.8780  Acc 1: 0.2143\n",
            "\n",
            "valid Loss: 0.3929 Acc: 0.2821 Balanced Acc: 0.4789  Acc 0: 0.6364  Acc 1: 0.3214\n",
            "\n",
            "Epoch 66/99\n",
            "----------\n",
            "train Loss: 0.4081 Acc: 0.2680 Balanced Acc: 0.5340  Acc 0: 0.8537  Acc 1: 0.2143\n",
            "\n",
            "valid Loss: 0.3990 Acc: 0.2821 Balanced Acc: 0.4610  Acc 0: 0.6364  Acc 1: 0.2857\n",
            "\n",
            "Epoch 67/99\n",
            "----------\n",
            "train Loss: 0.4051 Acc: 0.2680 Balanced Acc: 0.5450  Acc 0: 0.9024  Acc 1: 0.1875\n",
            "\n",
            "valid Loss: 0.3883 Acc: 0.2821 Balanced Acc: 0.5860  Acc 0: 0.6364  Acc 1: 0.5357\n",
            "\n",
            "Epoch 68/99\n",
            "----------\n",
            "train Loss: 0.4093 Acc: 0.2680 Balanced Acc: 0.4668  Acc 0: 0.5854  Acc 1: 0.3482\n",
            "\n",
            "valid Loss: 0.3971 Acc: 0.2821 Balanced Acc: 0.4610  Acc 0: 0.6364  Acc 1: 0.2857\n",
            "\n",
            "Epoch 69/99\n",
            "----------\n",
            "train Loss: 0.4059 Acc: 0.2680 Balanced Acc: 0.5448  Acc 0: 0.6341  Acc 1: 0.4554\n",
            "\n",
            "valid Loss: 0.3955 Acc: 0.2821 Balanced Acc: 0.4610  Acc 0: 0.6364  Acc 1: 0.2857\n",
            "\n",
            "Epoch 70/99\n",
            "----------\n",
            "train Loss: 0.4064 Acc: 0.2680 Balanced Acc: 0.5331  Acc 0: 0.7805  Acc 1: 0.2857\n",
            "\n",
            "valid Loss: 0.3879 Acc: 0.2821 Balanced Acc: 0.4968  Acc 0: 0.6364  Acc 1: 0.3571\n",
            "\n",
            "Epoch 71/99\n",
            "----------\n",
            "train Loss: 0.4089 Acc: 0.2680 Balanced Acc: 0.5328  Acc 0: 0.8780  Acc 1: 0.1875\n",
            "\n",
            "valid Loss: 0.3930 Acc: 0.2821 Balanced Acc: 0.5422  Acc 0: 0.7273  Acc 1: 0.3571\n",
            "\n",
            "Epoch 72/99\n",
            "----------\n",
            "train Loss: 0.4075 Acc: 0.2680 Balanced Acc: 0.5372  Acc 0: 0.8780  Acc 1: 0.1964\n",
            "\n",
            "valid Loss: 0.3946 Acc: 0.2821 Balanced Acc: 0.4870  Acc 0: 0.5455  Acc 1: 0.4286\n",
            "\n",
            "Epoch 73/99\n",
            "----------\n",
            "train Loss: 0.4067 Acc: 0.2680 Balanced Acc: 0.5575  Acc 0: 0.8293  Acc 1: 0.2857\n",
            "\n",
            "valid Loss: 0.3974 Acc: 0.2821 Balanced Acc: 0.5244  Acc 0: 0.7273  Acc 1: 0.3214\n",
            "\n",
            "Epoch 74/99\n",
            "----------\n",
            "train Loss: 0.4074 Acc: 0.2680 Balanced Acc: 0.5417  Acc 0: 0.8780  Acc 1: 0.2054\n",
            "\n",
            "valid Loss: 0.3928 Acc: 0.2821 Balanced Acc: 0.5406  Acc 0: 0.5455  Acc 1: 0.5357\n",
            "\n",
            "Epoch 75/99\n",
            "----------\n",
            "train Loss: 0.4045 Acc: 0.2680 Balanced Acc: 0.5507  Acc 0: 0.5122  Acc 1: 0.5893\n",
            "\n",
            "valid Loss: 0.4043 Acc: 0.2821 Balanced Acc: 0.4886  Acc 0: 0.7273  Acc 1: 0.2500\n",
            "\n",
            "Epoch 76/99\n",
            "----------\n",
            "train Loss: 0.4046 Acc: 0.2680 Balanced Acc: 0.5238  Acc 0: 0.8780  Acc 1: 0.1696\n",
            "\n",
            "valid Loss: 0.3939 Acc: 0.2821 Balanced Acc: 0.5584  Acc 0: 0.5455  Acc 1: 0.5714\n",
            "\n",
            "Epoch 77/99\n",
            "----------\n",
            "train Loss: 0.4072 Acc: 0.2680 Balanced Acc: 0.5683  Acc 0: 0.6098  Acc 1: 0.5268\n",
            "\n",
            "valid Loss: 0.3968 Acc: 0.2821 Balanced Acc: 0.4968  Acc 0: 0.6364  Acc 1: 0.3571\n",
            "\n",
            "Epoch 78/99\n",
            "----------\n",
            "train Loss: 0.4082 Acc: 0.2680 Balanced Acc: 0.5417  Acc 0: 0.8780  Acc 1: 0.2054\n",
            "\n",
            "valid Loss: 0.3944 Acc: 0.2821 Balanced Acc: 0.4610  Acc 0: 0.6364  Acc 1: 0.2857\n",
            "\n",
            "Epoch 79/99\n",
            "----------\n",
            "train Loss: 0.4084 Acc: 0.2680 Balanced Acc: 0.5328  Acc 0: 0.8780  Acc 1: 0.1875\n",
            "\n",
            "valid Loss: 0.3955 Acc: 0.2821 Balanced Acc: 0.4789  Acc 0: 0.6364  Acc 1: 0.3214\n",
            "\n",
            "Epoch 80/99\n",
            "----------\n",
            "train Loss: 0.4071 Acc: 0.2680 Balanced Acc: 0.5328  Acc 0: 0.8780  Acc 1: 0.1875\n",
            "\n",
            "valid Loss: 0.3964 Acc: 0.2821 Balanced Acc: 0.4789  Acc 0: 0.6364  Acc 1: 0.3214\n",
            "\n",
            "Epoch 81/99\n",
            "----------\n",
            "train Loss: 0.4082 Acc: 0.2680 Balanced Acc: 0.5372  Acc 0: 0.8780  Acc 1: 0.1964\n",
            "\n",
            "valid Loss: 0.3853 Acc: 0.2821 Balanced Acc: 0.5584  Acc 0: 0.5455  Acc 1: 0.5714\n",
            "\n",
            "Epoch 82/99\n",
            "----------\n",
            "train Loss: 0.4078 Acc: 0.2680 Balanced Acc: 0.5640  Acc 0: 0.8780  Acc 1: 0.2500\n",
            "\n",
            "valid Loss: 0.3933 Acc: 0.2821 Balanced Acc: 0.4968  Acc 0: 0.6364  Acc 1: 0.3571\n",
            "\n",
            "Epoch 83/99\n",
            "----------\n",
            "train Loss: 0.4070 Acc: 0.2680 Balanced Acc: 0.5462  Acc 0: 0.8780  Acc 1: 0.2143\n",
            "\n",
            "valid Loss: 0.3891 Acc: 0.2821 Balanced Acc: 0.5682  Acc 0: 0.6364  Acc 1: 0.5000\n",
            "\n",
            "Epoch 84/99\n",
            "----------\n",
            "train Loss: 0.4083 Acc: 0.2680 Balanced Acc: 0.5429  Acc 0: 0.8537  Acc 1: 0.2321\n",
            "\n",
            "valid Loss: 0.3928 Acc: 0.2821 Balanced Acc: 0.5146  Acc 0: 0.6364  Acc 1: 0.3929\n",
            "\n",
            "Epoch 85/99\n",
            "----------\n",
            "train Loss: 0.4082 Acc: 0.2680 Balanced Acc: 0.5599  Acc 0: 0.7805  Acc 1: 0.3393\n",
            "\n",
            "valid Loss: 0.4004 Acc: 0.2821 Balanced Acc: 0.4968  Acc 0: 0.6364  Acc 1: 0.3571\n",
            "\n",
            "Epoch 86/99\n",
            "----------\n",
            "train Loss: 0.4074 Acc: 0.2680 Balanced Acc: 0.5328  Acc 0: 0.8780  Acc 1: 0.1875\n",
            "\n",
            "valid Loss: 0.3985 Acc: 0.2821 Balanced Acc: 0.5065  Acc 0: 0.7273  Acc 1: 0.2857\n",
            "\n",
            "Epoch 87/99\n",
            "----------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.4065 Acc: 0.2680 Balanced Acc: 0.5420  Acc 0: 0.7805  Acc 1: 0.3036\n",
            "\n",
            "valid Loss: 0.3969 Acc: 0.2821 Balanced Acc: 0.5049  Acc 0: 0.5455  Acc 1: 0.4643\n",
            "\n",
            "Epoch 88/99\n",
            "----------\n",
            "train Loss: 0.4079 Acc: 0.2680 Balanced Acc: 0.5019  Acc 0: 0.7805  Acc 1: 0.2232\n",
            "\n",
            "valid Loss: 0.3945 Acc: 0.2821 Balanced Acc: 0.5422  Acc 0: 0.7273  Acc 1: 0.3571\n",
            "\n",
            "Epoch 89/99\n",
            "----------\n",
            "train Loss: 0.4086 Acc: 0.2680 Balanced Acc: 0.5462  Acc 0: 0.8780  Acc 1: 0.2143\n",
            "\n",
            "valid Loss: 0.3993 Acc: 0.2821 Balanced Acc: 0.5325  Acc 0: 0.6364  Acc 1: 0.4286\n",
            "\n",
            "Epoch 90/99\n",
            "----------\n",
            "train Loss: 0.4040 Acc: 0.2680 Balanced Acc: 0.5372  Acc 0: 0.8780  Acc 1: 0.1964\n",
            "\n",
            "valid Loss: 0.3934 Acc: 0.2821 Balanced Acc: 0.5049  Acc 0: 0.5455  Acc 1: 0.4643\n",
            "\n",
            "Epoch 91/99\n",
            "----------\n",
            "train Loss: 0.4079 Acc: 0.2680 Balanced Acc: 0.5632  Acc 0: 0.8049  Acc 1: 0.3214\n",
            "\n",
            "valid Loss: 0.3985 Acc: 0.2821 Balanced Acc: 0.5601  Acc 0: 0.7273  Acc 1: 0.3929\n",
            "\n",
            "Epoch 92/99\n",
            "----------\n",
            "train Loss: 0.4077 Acc: 0.2680 Balanced Acc: 0.5396  Acc 0: 0.8293  Acc 1: 0.2500\n",
            "\n",
            "valid Loss: 0.3938 Acc: 0.2821 Balanced Acc: 0.5422  Acc 0: 0.7273  Acc 1: 0.3571\n",
            "\n",
            "Epoch 93/99\n",
            "----------\n",
            "train Loss: 0.4075 Acc: 0.2680 Balanced Acc: 0.5384  Acc 0: 0.8537  Acc 1: 0.2232\n",
            "\n",
            "valid Loss: 0.4000 Acc: 0.2821 Balanced Acc: 0.4789  Acc 0: 0.6364  Acc 1: 0.3214\n",
            "\n",
            "Epoch 94/99\n",
            "----------\n",
            "train Loss: 0.4068 Acc: 0.2680 Balanced Acc: 0.5372  Acc 0: 0.8780  Acc 1: 0.1964\n",
            "\n",
            "valid Loss: 0.3904 Acc: 0.2821 Balanced Acc: 0.5503  Acc 0: 0.6364  Acc 1: 0.4643\n",
            "\n",
            "Epoch 95/99\n",
            "----------\n",
            "train Loss: 0.4080 Acc: 0.2680 Balanced Acc: 0.5352  Acc 0: 0.8293  Acc 1: 0.2411\n",
            "\n",
            "valid Loss: 0.3978 Acc: 0.2821 Balanced Acc: 0.4789  Acc 0: 0.6364  Acc 1: 0.3214\n",
            "\n",
            "Epoch 96/99\n",
            "----------\n",
            "train Loss: 0.4068 Acc: 0.2680 Balanced Acc: 0.5432  Acc 0: 0.7561  Acc 1: 0.3304\n",
            "\n",
            "valid Loss: 0.3929 Acc: 0.2821 Balanced Acc: 0.5065  Acc 0: 0.7273  Acc 1: 0.2857\n",
            "\n",
            "Epoch 97/99\n",
            "----------\n",
            "train Loss: 0.4075 Acc: 0.2680 Balanced Acc: 0.5328  Acc 0: 0.8780  Acc 1: 0.1875\n",
            "\n",
            "valid Loss: 0.3933 Acc: 0.2821 Balanced Acc: 0.5146  Acc 0: 0.6364  Acc 1: 0.3929\n",
            "\n",
            "Epoch 98/99\n",
            "----------\n",
            "train Loss: 0.4071 Acc: 0.2680 Balanced Acc: 0.5429  Acc 0: 0.8537  Acc 1: 0.2321\n",
            "\n",
            "valid Loss: 0.3920 Acc: 0.2821 Balanced Acc: 0.5422  Acc 0: 0.7273  Acc 1: 0.3571\n",
            "\n",
            "Epoch 99/99\n",
            "----------\n",
            "train Loss: 0.4055 Acc: 0.2680 Balanced Acc: 0.5429  Acc 0: 0.8537  Acc 1: 0.2321\n",
            "\n",
            "valid Loss: 0.3917 Acc: 0.2821 Balanced Acc: 0.4789  Acc 0: 0.6364  Acc 1: 0.3214\n",
            "\n",
            "Training complete in 159m 51s\n",
            "Best val Acc: 0.282051\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device=torch.device('cpu')\n",
        "\n",
        "datasets={'train':train_dataset,'valid':valid_dataset}\n",
        "dataloaders={'train':train_loader,'valid':valid_loader}\n",
        "\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.0001)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
        "\n",
        "#class_weight[0]=1\n",
        "#criterion=nn.L1Loss()\n",
        "#criterion=nn.MSELoss()\n",
        "criterion=nn.BCELoss()\n",
        "#criterion=nn.MSELoss()\n",
        "#criterion=nn.CrossEntropyLoss(weight=class_weight.to(device))\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.1)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epoch\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "\n",
        "num_epochs=100\n",
        "\n",
        "trained_model=train_model(datasets,dataloaders,model,criterion,optimizer,scheduler,num_epochs,device, class_weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SQ-g4rspvyV"
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwMPtH4ypvyW"
      },
      "outputs": [],
      "source": [
        "model=model.to(device)\n",
        "inputs, labels = next(iter(train_loader))\n",
        "inputs = inputs.to(device)\n",
        "labels=labels.type(torch.LongTensor).to(device)\n",
        "outputs=model(inputs.squeeze(0))\n",
        "\n",
        "p=torch.nn.functional.sigmoid(outputs)\n",
        "score=torch.ones((4,)).to(device)\n",
        "score[3]=1-torch.exp(-torch.sum(p[:,3],dim=0))\n",
        "score[2]=(1-score[3])*(1-torch.exp(-torch.sum(p[:,2],dim=0)))\n",
        "score[1]=(1-score[3])*(1-score[2])*(1-torch.exp(-torch.sum(p[:,1],dim=0)))\n",
        "score[0]=(1-score[3])*(1-score[2])*(1-score[1])*(1-torch.exp(-torch.sum(p[:,0],dim=0)))\n",
        "\n",
        "pred=torch.argmax(score)\n",
        "\n",
        "loss=criterion(score.unsqueeze(0),labels-1)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "#score=1-torch.exp(-torch.sum(p[:,2]))\n",
        "#loss=criterion(labels,score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maW1C6eppvyW",
        "outputId": "d5b3c371-4040-42e3-aee2-da4285567bab"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "expand(torch.cuda.FloatTensor{[2]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m p\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(outputs,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m score\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m score[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(p,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     10\u001b[0m score[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(p[:,\u001b[38;5;241m1\u001b[39m],dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
            "\u001b[1;31mRuntimeError\u001b[0m: expand(torch.cuda.FloatTensor{[2]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)"
          ]
        }
      ],
      "source": [
        "model=model.to(device)\n",
        "inputs, labels = next(iter(train_loader))\n",
        "inputs = inputs.to(device)\n",
        "labels=labels.type(torch.LongTensor).to(device)\n",
        "outputs=model(inputs.squeeze(0))\n",
        "\n",
        "p=torch.nn.functional.softmax(outputs,dim=1)\n",
        "score=torch.zeros(1,2).to(device)\n",
        "score[0,1]=1-torch.exp(-torch.sum(p[:,1],dim=0))\n",
        "score[0,0]=-torch.exp(-torch.sum(p[:,1],dim=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJMAGVHrpvyW",
        "outputId": "ad1a4017-9d86-4abe-a7ff-18962f7914ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0.]], device='cuda:0')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT7LHL_ppvyW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model=model.to(device)\n",
        "inputs = inputs.to(device)\n",
        "labels=labels.type(torch.LongTensor).to(device)\n",
        "outputs = model(inputs.squeeze(0))\n",
        "\n",
        "p=torch.nn.functional.sigmoid(outputs)\n",
        "score=1-torch.exp(-torch.sum(p,dim=0))\n",
        "#p=torch.nn.functional.softmax(outputs,dim=1)\n",
        "#score=torch.zeros(1,2).to(device)\n",
        "#score[0,1]=1-torch.exp(-torch.sum(p,dim=0))\n",
        "#score[0,0]=-torch.exp(-torch.sum(p[:,1],dim=0))\n",
        "criterion=nn.BCELoss()\n",
        "loss=criterion(score,labels.type(torch.FloatTensor).to(device))\n",
        "\n",
        "\n",
        "#criterion=nn.L1Loss()\n",
        "#loss=criterion(score,labels)\n",
        "print(outputs)\n",
        "print(score)\n",
        "print(labels)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-quLA1cpvyW"
      },
      "outputs": [],
      "source": [
        "mean_loss=0;\n",
        "count=0;\n",
        "batch_score=torch.zeros((10,1))\n",
        "batch_labels=torch.zeros((10,1))\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.0001)\n",
        "\n",
        "count=0\n",
        "num_epochs=50\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    running_loss=0\n",
        "    for inputs, labels in (train_loader):\n",
        "\n",
        "        if(count==10):\n",
        "            count=0\n",
        "            batch_score=torch.zeros((10,1))\n",
        "            batch_labels=torch.zeros((10,1))\n",
        "\n",
        "\n",
        "        model=model.to(device)\n",
        "        inputs = inputs.to(device)\n",
        "        labels=labels.type(torch.LongTensor).to(device)\n",
        "        outputs = model(inputs.squeeze(0))\n",
        "\n",
        "        p=torch.nn.functional.sigmoid(outputs)\n",
        "        score=1-torch.exp(-torch.sum(p,dim=0))\n",
        "        #p=torch.nn.functional.softmax(outputs,dim=1)\n",
        "        #score=torch.zeros(1,2).to(device)\n",
        "        #score[0,1]=1-torch.exp(-torch.sum(p,dim=0))\n",
        "        #score[0,0]=-torch.exp(-torch.sum(p[:,1],dim=0))\n",
        "\n",
        "        batch_score[count]=score\n",
        "        batch_labels[count]=labels.type(torch.FloatTensor)\n",
        "        #obs_loss=criterion(score,labels.type(torch.FloatTensor).to(device))\n",
        "        #if(labels==1):\n",
        "        #    loss=loss+class_weight[1]*obs_loss\n",
        "        #else:\n",
        "        #    loss=loss+class_weight[0]*obs_loss\n",
        "\n",
        "        #mean_loss=mean_loss+loss.item()\n",
        "        count=count+1\n",
        "        if (count==9):\n",
        "            loss=criterion(batch_score, batch_labels)\n",
        "            running_loss += loss.item()*10\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    epoch_loss = running_loss/len(train_dataset)\n",
        "    print('{} Loss: {:.4f} '.format('Train', epoch_loss))\n",
        "    #print(mean_loss/count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k5rHgvipvyW"
      },
      "outputs": [],
      "source": [
        "data_label=[]\n",
        "data_estimate=[]\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "for inputs, labels in (train_loader):\n",
        "\n",
        "    model=model.to(device)\n",
        "    inputs = inputs.to(device)\n",
        "    labels=labels.type(torch.LongTensor).to(device)\n",
        "    outputs = model(inputs.squeeze(0))\n",
        "\n",
        "    p=torch.nn.functional.sigmoid(outputs)\n",
        "    score=1-torch.exp(-torch.sum(p,dim=0))\n",
        "    data_estimate.append(score)\n",
        "    data_label.append(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaZRrUllpvyW"
      },
      "outputs": [],
      "source": [
        "error=0\n",
        "for ct in range(165):\n",
        "    error=error+((data_estimate[ct]>0.5)==data_label[ct])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SEwGduvpvyW"
      },
      "outputs": [],
      "source": [
        "data_estimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK_KoH5tpvyW"
      },
      "outputs": [],
      "source": [
        "score"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}